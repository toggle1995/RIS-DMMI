# RIS-DMMI
This repository provides the PyTorch implementation of DMMI in the following papers:<br />
__Beyond One-to-One: Rethinking the Referring Image Segmentation (ICCV2023)__ <br />

# Dataset
We collect a new comprehensive dataset Ref-ZOM (**Z**ero/**O**ne/**M**any), which contains image-text pairs in one-to-zero, one-to-one and one-to-many conditions. Similar to RefCOCO, RefCOCO+ and G-Ref, all the images in Ref-ZOM are selected from COCO dataset. Here, we provide the text, image and annotation information of Ref-ZOM, which should be utilized with COCO_trainval2014 together. <br />
Our dataset could be downloaded from:<br />
[[Baidu Cloud](https://pan.baidu.com/s/1CxPYGWEadHhcViTH2iI7jw?pwd=g7uu)] [Google Drive]<br />
Remember to download original COCO dataset from:<br />
[[COCO Dowanload](https://cocodataset.org/#download)]<br />

# Code
The code will be provided soon.

